{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cdiscount-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50 as CNN\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities import utils\n",
    "from utilities.BSONIterator import BSONIterator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-eebdf82da9fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_results_reproducible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Carvana\\Cdiscount\\utilities\\utils.py\u001b[0m in \u001b[0;36mset_results_reproducible\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PYTHONHASHSEED'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12345\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[0msession_conf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintra_op_parallelism_threads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minter_op_parallelism_threads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rn' is not defined"
     ]
    }
   ],
   "source": [
    "utils.set_results_reproducible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Lookup Tables\n",
    "First load the lookup tables from the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_df = pd.read_csv(\"inputs/categories.csv\", index_col=0)\n",
    "cat2idx, idx2cat = utils.make_category_tables(categories_df)\n",
    "\n",
    "train_offsets_df = pd.read_csv(\"inputs/train_offsets.csv\", index_col=0)\n",
    "train_images_df = pd.read_csv(\"inputs/train_images.csv\", index_col=0)\n",
    "val_images_df = pd.read_csv(\"inputs/val_images.csv\", index_col=0)\n",
    "\n",
    "#test_offsets_df = pd.read_csv(\"inputs/test_offsets.csv\", index_col=0)\n",
    "#test_images_df = pd.read_csv(\"inputs/test_images.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Some Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"inputs/\"\n",
    "\n",
    "#train_bson_path = os.path.join(data_dir, \"train.bson\")\n",
    "#num_train_products = 7069896\n",
    "\n",
    "train_bson_path = \"inputs/train_example.bson\"\n",
    "num_train_products = 82\n",
    "\n",
    "#test_bson_path = os.path.join(data_dir, \"test.bson\")\n",
    "#num_test_products = 1768172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 5270 classes.\n",
      "Found 10 images belonging to 5270 classes.\n"
     ]
    }
   ],
   "source": [
    "train_bson_file = open(train_bson_path, \"rb\")\n",
    "\n",
    "num_classes = 5270\n",
    "batch_size = 128\n",
    "input_size = 197 #180\n",
    "num_train_images = len(train_images_df)\n",
    "num_val_images = len(val_images_df)\n",
    "\n",
    "\n",
    "# Tip: use ImageDataGenerator for data augmentation and preprocessing.\n",
    "train_datagen = ImageDataGenerator()\n",
    "train_gen = BSONIterator(train_bson_file, train_images_df, train_offsets_df, num_classes, \n",
    "                         train_datagen, target_size=(input_size, input_size),\n",
    "                         batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_gen = BSONIterator(train_bson_file, val_images_df, train_offsets_df, num_classes,\n",
    "                       val_datagen, target_size=(input_size, input_size),\n",
    "                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CNN(include_top=False, input_shape=(input_size, input_size, 3), weights=None)\n",
    "model.load_weights('weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "classifier = Dense(num_classes, activation='softmax')(model.output)\n",
    "\n",
    "model = Model(inputs=model.input, outputs=classifier)\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_layer = -2\n",
    "\n",
    "for layer in model.layers[:index_layer]: layer.trainable=False\n",
    "for layer in model.layers[index_layer:]: layer.trainable=True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7ba2bac548bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrun_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_run_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weights/{}.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ResNet50-last_FC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mweights_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'weights/{}.hdf5'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Carvana\\Cdiscount\\utilities\\utils.py\u001b[0m in \u001b[0;36mget_run_name\u001b[1;34m(weights_file, model_name)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_run_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mrun_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{0}-{1:%Y-%m-%d-%H%M}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "run_name = utils.get_run_name('weights/{}.hdf5', 'ResNet50-last_FC')\n",
    "weights_path = 'weights/{}.hdf5'.format(run_name)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_binary_accuracy',\n",
    "                           patience=8,\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4,\n",
    "                           mode='max'),\n",
    "             ReduceLROnPlateau(monitor='val_binary_accuracy',\n",
    "                               factor=0.1,\n",
    "                               patience=4,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_binary_accuracy',\n",
    "                             filepath=weights_path,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='max'),\n",
    "             TensorBoard(log_dir='logs/{}'.format(run_name), batch_size=batch_size)]\n",
    "\n",
    "# To train the model:\n",
    "print('Starting run \"{}\"'.format(run_name))\n",
    "model.fit_generator(train_gen,\n",
    "                    steps_per_epoch = num_train_images // batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data = val_gen,\n",
    "                    validation_steps = num_val_images // batch_size,\n",
    "                    workers = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bson_file = open(test_bson_path, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_gen = BSONIterator(test_bson_file, test_images_df, test_offsets_df,\n",
    "                        num_classes, test_datagen, batch_size=batch_size, \n",
    "                        with_labels=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running model.predict_generator() gives a list of 3095080 predictions, one for each image.\n",
    "\n",
    "The indices of the predictions correspond to the indices in test_images_df. After making the predictions, you probably want to average the predictions for products that have multiple images.\n",
    "\n",
    "Use idx2cat[] to convert the predicted category index back to the original class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_test_samples = len(test_images_df)\n",
    "predictions = model.predict_generator(test_gen, steps=num_test_samples // batch_size, workers=8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ah yes, the code to generate the predictions needs a lot of RAM. I only tested it on a small portion of the test set and did not realize it would take so much memory. I actually use a different way to do it now, which is to predict a mini-batch per product, so the mini batch contains either 1, 2, 3 or 4 images, and then only store the category ID, not the full prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some people mentioned earlier that they got errors on bson.BSON.decode(). I was not able to reproduce this until just now. It turns out that using ImageDataGenerator with certain data augmentation options causes this to happen.\n",
    "\n",
    "If you use rotation_range, width_shift_range, height_shift_range, shear_range, or zoom_range, then the BSON decoding gets messed up for some reason. I don't understand why but all these augmentation options use a transformation matrix, and so maybe the code that applies this matrix to the image has a bug and overwrites memory. But that is just a guess.\n",
    "\n",
    "Interestingly enough, the data augmentation options that do not use this transformation matrix, such as channel_shift_range and horizontal_flip work just fine..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some handy codes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To evaluate on the validation set:\n",
    "model.evaluate_generator(val_gen, steps=num_val_images // batch_size, workers=8)\n",
    "\n",
    "pred = model.predict_generator(train_gen, steps=num_train_images/batch_size, workers=8, verbose=1)\n",
    "utils.save_array('test.hdf5', pred)\n",
    "\n",
    "new_pred = new_model.predict_generator(train_gen, steps=num_train_images/batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# How fast is the generator? Create a single batch:\n",
    "# CPU times: user 172 ms, sys: 108 ms, total: 280 ms\n",
    "# Wall time: 381 ms\n",
    "\n",
    "next(train_gen)  # warm-up\n",
    "%time bx, by = next(train_gen)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Does it really output images and one-hot encoded class labels?\n",
    "# Note that the images are pre-processed (and augmented) and therefore may look weird.\n",
    "\n",
    "plt.imshow(bx[-1].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cat_idx = np.argmax(by[-1])\n",
    "cat_id = idx2cat[cat_idx]\n",
    "categories_df.loc[cat_id]\n",
    "\n",
    "#category_level1    DECO - LINGE - LUMINAIRE\n",
    "#category_level2           COUSSIN ET HOUSSE\n",
    "#category_level3                     COUSSIN\n",
    "#category_idx                           1666\n",
    "#Name: 1000001703, dtype: object"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CPU times: user 172 ms, sys: 12 ms, total: 184 ms\n",
    "# Wall time: 203 ms\n",
    "\n",
    "%time bx, by = next(val_gen)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.imshow(bx[-1].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cat_idx = np.argmax(by[-1])\n",
    "cat_id = idx2cat[cat_idx]\n",
    "categories_df.loc[cat_id]\n",
    "\n",
    "#category_level1                      TELEPHONIE - GPS\n",
    "#category_level2                  ACCESSOIRE TELEPHONE\n",
    "#category_level3    COQUE TELEPHONE - BUMPER TELEPHONE\n",
    "#category_idx                                     5055\n",
    "#Name: 1000010653, dtype: object"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
