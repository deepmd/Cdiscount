{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cdiscount-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50 as CNN\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "import keras.backend as K\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "from utilities import utils\n",
    "from utilities.BSONIterator import BSONIterator\n",
    "from optimizers.AdamAccumulate import AdamAccumulate\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.set_results_reproducible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Lookup Tables\n",
    "First load the lookup tables from the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dariush/anaconda3/envs/deep1/lib/python3.6/site-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "categories_df = pd.read_csv(\"inputs/categories.csv\", encoding = \"ISO-8859-1\", index_col=0)\n",
    "cat2idx, idx2cat = utils.make_category_tables(categories_df)\n",
    "\n",
    "train_offsets_df = pd.read_csv(\"inputs/train_offsets.csv\", encoding = \"ISO-8859-1\", index_col=0)\n",
    "train_images_df = pd.read_csv(\"inputs/train_images.csv\", encoding = \"ISO-8859-1\", index_col=0)\n",
    "val_images_df = pd.read_csv(\"inputs/val_images.csv\", encoding = \"ISO-8859-1\", index_col=0)\n",
    "\n",
    "#test_offsets_df = pd.read_csv(\"inputs/test_offsets.csv\", index_col=0)\n",
    "#test_images_df = pd.read_csv(\"inputs/test_images.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Some Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"inputs/\"\n",
    "\n",
    "train_bson_path = os.path.join(data_dir, \"train.bson\")\n",
    "num_train_products = 7069896\n",
    "\n",
    "#train_bson_path = \"inputs/train_example.bson\"\n",
    "#num_train_products = 82\n",
    "\n",
    "#test_bson_path = os.path.join(data_dir, \"test.bson\")\n",
    "#num_test_products = 1768172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9901521 images belonging to 5270 classes.\n",
      "Found 2469772 images belonging to 5270 classes.\n"
     ]
    }
   ],
   "source": [
    "train_bson_file = open(train_bson_path, \"rb\")\n",
    "\n",
    "num_classes = 5270\n",
    "batch_size = 92\n",
    "input_size = 197 #180\n",
    "num_train_images = len(train_images_df)\n",
    "num_val_images = len(val_images_df)\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Tip: use ImageDataGenerator for data augmentation and preprocessing.\n",
    "train_datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
    "       height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, \n",
    "       channel_shift_range=10., horizontal_flip=True)\n",
    "train_gen = BSONIterator(train_bson_file, train_images_df, train_offsets_df, num_classes, \n",
    "                         train_datagen, lock, target_size=(input_size, input_size),\n",
    "                         batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_gen = BSONIterator(train_bson_file, val_images_df, train_offsets_df, num_classes,\n",
    "                       val_datagen, lock, target_size=(input_size, input_size),\n",
    "                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CNN(include_top=False, input_shape=(input_size, input_size, 3), weights=None)\n",
    "#model.load_weights('weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "flatten_output = Flatten()(model.output)\n",
    "classifier = Dense(num_classes, activation='softmax')(flatten_output)\n",
    "\n",
    "model = Model(inputs=model.input, outputs=classifier)\n",
    "\n",
    "model.compile(optimizer=AdamAccumulate(accum_iters=2),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first layer of conv4_x (28th trainable layer from top including fc) --> refer to ResNet50 structure\n",
    "index_layer = -97 \n",
    "\n",
    "for layer in model.layers[:index_layer]: layer.trainable=False\n",
    "for layer in model.layers[index_layer:]: layer.trainable=True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run \"ResNet50-2017-10-12-1846\"\n",
      "Epoch 1/50\n",
      "    62/107625 [..............................] - ETA: 97654s - loss: 1.8415 - acc: 0.6104"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "run_name = utils.get_run_name('weights/{}.hdf5', 'ResNet50')\n",
    "weights_path = 'weights/{}.hdf5'.format(run_name)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_acc',\n",
    "                           patience=3,\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4,\n",
    "                           mode='max'),\n",
    "             ReduceLROnPlateau(monitor='val_acc',\n",
    "                               factor=0.1,\n",
    "                               patience=2,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_acc',\n",
    "                             filepath=weights_path,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='max'),\n",
    "             TensorBoard(log_dir='logs/{}'.format(run_name), batch_size=batch_size)]\n",
    "\n",
    "model.load_weights(\"weights/ResNet50-2017-10-10-0014.hdf5\")\n",
    "K.set_value(model.optimizer.lr, 2e-4)\n",
    "\n",
    "# To train the model:\n",
    "print('Starting run \"{}\"'.format(run_name))\n",
    "model.fit_generator(train_gen,\n",
    "                    steps_per_epoch = num_train_images // batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data = val_gen,\n",
    "                    validation_steps = num_val_images // batch_size,\n",
    "                    workers = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_bson_file = open(test_bson_path, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_gen = BSONIterator(test_bson_file, test_images_df, test_offsets_df,\n",
    "                        num_classes, test_datagen, batch_size=batch_size, \n",
    "                        with_labels=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Running model.predict_generator() gives a list of 3095080 predictions, one for each image.\n",
    "\n",
    "The indices of the predictions correspond to the indices in test_images_df. After making the predictions, you probably want to average the predictions for products that have multiple images.\n",
    "\n",
    "Use idx2cat[] to convert the predicted category index back to the original class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_test_samples = len(test_images_df)\n",
    "predictions = model.predict_generator(test_gen, steps=num_test_samples // batch_size, workers=8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ah yes, the code to generate the predictions needs a lot of RAM. I only tested it on a small portion of the test set and did not realize it would take so much memory. I actually use a different way to do it now, which is to predict a mini-batch per product, so the mini batch contains either 1, 2, 3 or 4 images, and then only store the category ID, not the full prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Some people mentioned earlier that they got errors on bson.BSON.decode(). I was not able to reproduce this until just now. It turns out that using ImageDataGenerator with certain data augmentation options causes this to happen.\n",
    "\n",
    "If you use rotation_range, width_shift_range, height_shift_range, shear_range, or zoom_range, then the BSON decoding gets messed up for some reason. I don't understand why but all these augmentation options use a transformation matrix, and so maybe the code that applies this matrix to the image has a bug and overwrites memory. But that is just a guess.\n",
    "\n",
    "Interestingly enough, the data augmentation options that do not use this transformation matrix, such as channel_shift_range and horizontal_flip work just fine..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Some handy codes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# To evaluate on the validation set:\n",
    "model.evaluate_generator(val_gen, steps=num_val_images // batch_size, workers=8)\n",
    "\n",
    "pred = model.predict_generator(train_gen, steps=num_train_images/batch_size, workers=8, verbose=1)\n",
    "utils.save_array('test.hdf5', pred)\n",
    "\n",
    "new_pred = new_model.predict_generator(train_gen, steps=num_train_images/batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# How fast is the generator? Create a single batch:\n",
    "# CPU times: user 172 ms, sys: 108 ms, total: 280 ms\n",
    "# Wall time: 381 ms\n",
    "\n",
    "next(train_gen)  # warm-up\n",
    "%time bx, by = next(train_gen)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Does it really output images and one-hot encoded class labels?\n",
    "# Note that the images are pre-processed (and augmented) and therefore may look weird.\n",
    "\n",
    "plt.imshow(bx[-1].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "cat_idx = np.argmax(by[-1])\n",
    "cat_id = idx2cat[cat_idx]\n",
    "categories_df.loc[cat_id]\n",
    "\n",
    "#category_level1    DECO - LINGE - LUMINAIRE\n",
    "#category_level2           COUSSIN ET HOUSSE\n",
    "#category_level3                     COUSSIN\n",
    "#category_idx                           1666\n",
    "#Name: 1000001703, dtype: object"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# CPU times: user 172 ms, sys: 12 ms, total: 184 ms\n",
    "# Wall time: 203 ms\n",
    "\n",
    "%time bx, by = next(val_gen)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "plt.imshow(bx[-1].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "cat_idx = np.argmax(by[-1])\n",
    "cat_id = idx2cat[cat_idx]\n",
    "categories_df.loc[cat_id]\n",
    "\n",
    "#category_level1                      TELEPHONIE - GPS\n",
    "#category_level2                  ACCESSOIRE TELEPHONE\n",
    "#category_level3    COQUE TELEPHONE - BUMPER TELEPHONE\n",
    "#category_idx                                     5055\n",
    "#Name: 1000010653, dtype: object"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
